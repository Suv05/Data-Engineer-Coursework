# ğŸ§  Retail Orders Data Engineering & Analytics Project (Databricks)

This project demonstrates a complete data engineering and analytics pipeline using **Apache Spark in Databricks**. The goal was to simulate a **real-world retail data workflow**, including:

- Data ingestion
- Data validation
- Cleaning and transformation
- Efficient storage
- Advanced visual analytics

All tasks were performed **entirely within the Databricks environment**, making use of PySpark and interactive dashboards.

---

## ğŸ“¦ Dataset Overview

The dataset mimics a **retail e-commerce orders system** with the following features:

- 25+ columns including order metadata, customer segmentation, product pricing, discounts, promotions, delivery dates, and ratings.
- Complexities such as:
  - Missing and null values
  - Invalid formats (e.g., `INVALID_DATE`)
  - Duplicate rows
  - Inconsistent schemas (booleans as strings, negative prices, etc.)

---

## ğŸ”„ Project Workflow

### âœ… 1. Data Ingestion
- Imported raw CSV into Databricks using the FileStore/DBFS.
- Inferred schema and read as a Spark DataFrame.

### âœ… 2. Data Validation
- Detected missing/null fields across critical columns.
- Checked for:
  - Negative or zero pricing
  - Out-of-bound ratings
  - Invalid dates
  - Duplicated rows
  - Blank or NULL `ProductID`, `CustomerID`, `OrderDate`

### âœ… 3. Data Cleaning & Transformation
- Cleaned and cast date fields to `DateType`.
- Replaced invalid/NULL entries with default values or averages.
- Standardized boolean fields (`TRUE` / `FALSE` â†’ `True` / `False`).
- Calculated new fields:
  - `TotalPrice = Quantity * UnitPrice`
  - `DeliveryTimeDays = DeliveryDate - OrderDate`
  - `IsDelayedDelivery`
- Extracted time-based features (Year, Month).

### âœ… 4. Data Storage
- Saved the cleaned and transformed dataset in **Parquet format** for optimized performance and storage.

### âœ… 5. Interactive Dashboards (Visual Analytics)
Used Databricks dashboards to visualize insights and monitor key performance metrics:

---

## ğŸ“Š Dashboards & Insights

### ğŸ§® Customer Lifetime Value vs Number of Orders
![Customer lifetime value vs number of orders](/image/image.png)

---

### ğŸšš Shipping Status Distribution
![Shipping status distribution](/image/image-1.png)

---

### ğŸŒ Shipping Performance by Country and Status
![Shipping performance by country and status](/image/image-2.png)

---

### ğŸ” Customer Order Frequency Distribution
![Customer order frequency distribution](/image/image-3.png)

---

### ğŸ“… Daily Sales with 7-Day Moving Average
![Daily sales with 7-day moving average](/image/image-4.png)

---

### ğŸ’° Revenue by Customer Segment
![Revenue by customer segment](/image/image-5.png)

---

### ğŸŒ Order Distribution by Country
![Order distribution By country](/image/image-6.png)

---

### ğŸ“ˆ Order Trends Over Time
![Order trends over time](/image/image-7.png)

---

### ğŸ•’ Daily Sales (Smoothed View)
![Daily sales with 7-day moving avg ](/image/image-8.png)

---

## ğŸ› ï¸ Tools Used
- **Apache Spark (PySpark)** â€” scalable data processing
- **Databricks Notebook** â€” unified development environment
- **Databricks SQL & Dashboards** â€” for visual analytics
- **Parquet Format** â€” optimized data storage

---

## ğŸ Outcomes
- ğŸš€ Complete hands-on practice in a near-production setup
- âœ… Cleaned & transformed retail dataset using PySpark
- ğŸ“ˆ Multiple business insights generated via dashboards
- ğŸ”„ Ready for integration with BigQuery or Power BI

---

## ğŸ“š Future Scope
- Integrate BigQuery for warehousing
- Build Power BI reports using cleaned data
- Extend dataset to support ML (churn prediction, CLTV modeling)
