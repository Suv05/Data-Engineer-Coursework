{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "99d07057-fce0-40a1-8f4b-93fe25b7a516",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "66a17d2b-0f6a-4286-8c4e-a7917d61e317",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# üîß SOLUTION 1: Check if Spark session exists, create if needed\n",
    "def get_spark_session():\n",
    "    try:\n",
    "        # Try to get existing active session\n",
    "        spark = SparkSession.getActiveSession()\n",
    "        if spark is None:\n",
    "            # Create new session if none exists\n",
    "            spark = SparkSession.builder \\\n",
    "                .appName(\"OrderDataAnalysis\") \\\n",
    "                .getOrCreate()\n",
    "        return spark\n",
    "    except:\n",
    "        # If anything goes wrong, create fresh session\n",
    "        spark = SparkSession.builder \\\n",
    "            .appName(\"OrderDataAnalysis\") \\\n",
    "            .getOrCreate()\n",
    "        return spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ac7199-585f-4b19-bd6d-17263cb66e68",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get or create Spark session\n",
    "spark = get_spark_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "eb724dc0-f76b-4a60-acc0-0f16344c7762",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Spark Session Status:\n",
      "   App Name: OrderDataAnalysis\n",
      "   Master: yarn\n",
      "   Spark Version: 3.5.3\n",
      "   Active: True\n"
     ]
    }
   ],
   "source": [
    "print(\"‚úÖ Spark Session Status:\")\n",
    "print(f\"   App Name: {spark.sparkContext.appName}\")\n",
    "print(f\"   Master: {spark.sparkContext.master}\")\n",
    "print(f\"   Spark Version: {spark.version}\")\n",
    "print(f\"   Active: {not spark.sparkContext._jsc.sc().isStopped()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "29c147f6-5b3c-45ee-806b-91e809cc921e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define GCS paths using gs:// format (more efficient than https://)\n",
    "input_file_path = \"gs://my-dataproc-data-bucket-051203/data/order_data.csv\"\n",
    "output_path = \"gs://my-dataproc-data-bucket-051203/output/product_sales_insights\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bcb73c8d-17fb-4c83-8b8c-2929acd289f3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Reading Order Data from GCS ===\n",
      "Reading data from: gs://my-dataproc-data-bucket-051203/data/order_data.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Data successfully loaded from GCS!\n",
      "\n",
      "üìä Dataset Overview:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of records: 22\n",
      "Number of columns: 8\n",
      "\n",
      "üìã Data Schema:\n",
      "root\n",
      " |-- OrderID: string (nullable = true)\n",
      " |-- CustomerID: string (nullable = true)\n",
      " |-- ProductID: string (nullable = true)\n",
      " |-- ProductName: string (nullable = true)\n",
      " |-- Quantity: integer (nullable = true)\n",
      " |-- UnitPrice: double (nullable = true)\n",
      " |-- OrderDate: date (nullable = true)\n",
      " |-- Country: string (nullable = true)\n",
      "\n",
      "\n",
      "üìù Column Names:\n",
      "1. OrderID\n",
      "2. CustomerID\n",
      "3. ProductID\n",
      "4. ProductName\n",
      "5. Quantity\n",
      "6. UnitPrice\n",
      "7. OrderDate\n",
      "8. Country\n",
      "\n",
      "üîç First 10 rows of data:\n",
      "+-------+----------+---------+----------------+--------+---------+----------+---------+\n",
      "|OrderID|CustomerID|ProductID|ProductName     |Quantity|UnitPrice|OrderDate |Country  |\n",
      "+-------+----------+---------+----------------+--------+---------+----------+---------+\n",
      "|ORD001 |CUST101   |PROD001  |Laptop A        |1       |1200.0   |2024-01-15|USA      |\n",
      "|ORD001 |CUST101   |PROD003  |Mouse XYZ       |2       |25.5     |2024-01-15|USA      |\n",
      "|ORD002 |CUST102   |PROD002  |Smartphone B    |1       |850.0    |2024-01-16|Canada   |\n",
      "|ORD003 |CUST101   |PROD004  |Keyboard Pro    |1       |75.0     |2024-01-17|USA      |\n",
      "|ORD003 |CUST101   |PROD005  |Webcam HD       |1       |49.99    |2024-01-17|USA      |\n",
      "|ORD004 |CUST103   |PROD001  |Laptop A        |1       |1200.0   |2024-01-18|UK       |\n",
      "|ORD004 |CUST103   |PROD006  |Monitor 27in    |1       |300.0    |2024-01-18|UK       |\n",
      "|ORD005 |CUST104   |PROD007  |Headphones ANC  |1       |199.99   |2024-01-19|Australia|\n",
      "|ORD006 |CUST105   |PROD008  |External SSD 1TB|1       |150.0    |2024-01-20|USA      |\n",
      "|ORD006 |CUST105   |PROD003  |Mouse XYZ       |1       |25.5     |2024-01-20|USA      |\n",
      "+-------+----------+---------+----------------+--------+---------+----------+---------+\n",
      "only showing top 10 rows\n",
      "\n",
      "\n",
      "üîç Null Value Check:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+---------+-----------+--------+---------+---------+-------+\n",
      "|OrderID|CustomerID|ProductID|ProductName|Quantity|UnitPrice|OrderDate|Country|\n",
      "+-------+----------+---------+-----------+--------+---------+---------+-------+\n",
      "|      0|         0|        0|          0|       0|        0|        0|      0|\n",
      "+-------+----------+---------+-----------+--------+---------+---------+-------+\n",
      "\n",
      "\n",
      "üìà Basic Statistics:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/06/25 15:30:06 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+----------+---------+----------------+------------------+------------------+---------+\n",
      "|summary|OrderID|CustomerID|ProductID|     ProductName|          Quantity|         UnitPrice|  Country|\n",
      "+-------+-------+----------+---------+----------------+------------------+------------------+---------+\n",
      "|  count|     22|        22|       22|              22|                22|                22|       22|\n",
      "|   mean|   NULL|      NULL|     NULL|            NULL|1.1818181818181819|362.11090909090905|     NULL|\n",
      "| stddev|   NULL|      NULL|     NULL|            NULL|0.5010810823432181| 407.0944619514188|     NULL|\n",
      "|    min| ORD001|   CUST101|  PROD001|External SSD 1TB|                 1|              25.5|Australia|\n",
      "|    max| ORD017|   CUST110|  PROD010|       Webcam HD|                 3|            1200.0|      USA|\n",
      "+-------+-------+----------+---------+----------------+------------------+------------------+---------+\n",
      "\n",
      "\n",
      "üè∑Ô∏è Data Types:\n",
      "OrderID: StringType()\n",
      "CustomerID: StringType()\n",
      "ProductID: StringType()\n",
      "ProductName: StringType()\n",
      "Quantity: IntegerType()\n",
      "UnitPrice: DoubleType()\n",
      "OrderDate: DateType()\n",
      "Country: StringType()\n",
      "\n",
      "üî¢ Unique Value Counts:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 12:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CustomerID: 10 unique values\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ProductID: 10 unique values\n",
      "ProductName: 10 unique values\n",
      "Country: 7 unique values\n",
      "\n",
      "‚úÖ Data Quality Checks:\n",
      "Duplicate rows: 0\n",
      "Date range: 2024-01-15 to 2024-01-31\n",
      "Negative quantities: 0\n",
      "Negative prices: 0\n",
      "\n",
      "üåç Sample records by Country:\n",
      "\n",
      "--- Germany ---\n",
      "+-------+----------+---------+------------+--------+---------+----------+-------+\n",
      "|OrderID|CustomerID|ProductID|ProductName |Quantity|UnitPrice|OrderDate |Country|\n",
      "+-------+----------+---------+------------+--------+---------+----------+-------+\n",
      "|ORD008 |CUST106   |PROD010  |Smartwatch X|1       |299.99   |2024-01-22|Germany|\n",
      "+-------+----------+---------+------------+--------+---------+----------+-------+\n",
      "\n",
      "\n",
      "--- Canada ---\n",
      "+-------+----------+---------+----------------+--------+---------+----------+-------+\n",
      "|OrderID|CustomerID|ProductID|ProductName     |Quantity|UnitPrice|OrderDate |Country|\n",
      "+-------+----------+---------+----------------+--------+---------+----------+-------+\n",
      "|ORD002 |CUST102   |PROD002  |Smartphone B    |1       |850.0    |2024-01-16|Canada |\n",
      "|ORD007 |CUST102   |PROD009  |Printer Laser   |1       |220.0    |2024-01-21|Canada |\n",
      "|ORD015 |CUST102   |PROD008  |External SSD 1TB|1       |150.0    |2024-01-29|Canada |\n",
      "+-------+----------+---------+----------------+--------+---------+----------+-------+\n",
      "\n",
      "\n",
      "--- Japan ---\n",
      "+-------+----------+---------+--------------+--------+---------+----------+-------+\n",
      "|OrderID|CustomerID|ProductID|ProductName   |Quantity|UnitPrice|OrderDate |Country|\n",
      "+-------+----------+---------+--------------+--------+---------+----------+-------+\n",
      "|ORD012 |CUST109   |PROD007  |Headphones ANC|1       |199.99   |2024-01-26|Japan  |\n",
      "+-------+----------+---------+--------------+--------+---------+----------+-------+\n",
      "\n",
      "\n",
      "--- UK ---\n",
      "+-------+----------+---------+------------+--------+---------+----------+-------+\n",
      "|OrderID|CustomerID|ProductID|ProductName |Quantity|UnitPrice|OrderDate |Country|\n",
      "+-------+----------+---------+------------+--------+---------+----------+-------+\n",
      "|ORD004 |CUST103   |PROD001  |Laptop A    |1       |1200.0   |2024-01-18|UK     |\n",
      "|ORD004 |CUST103   |PROD006  |Monitor 27in|1       |300.0    |2024-01-18|UK     |\n",
      "|ORD014 |CUST110   |PROD006  |Monitor 27in|1       |300.0    |2024-01-28|UK     |\n",
      "+-------+----------+---------+------------+--------+---------+----------+-------+\n",
      "only showing top 3 rows\n",
      "\n",
      "\n",
      "--- France ---\n",
      "+-------+----------+---------+------------+--------+---------+----------+-------+\n",
      "|OrderID|CustomerID|ProductID|ProductName |Quantity|UnitPrice|OrderDate |Country|\n",
      "+-------+----------+---------+------------+--------+---------+----------+-------+\n",
      "|ORD010 |CUST107   |PROD004  |Keyboard Pro|2       |75.0     |2024-01-24|France |\n",
      "+-------+----------+---------+------------+--------+---------+----------+-------+\n",
      "\n",
      "\n",
      "üéâ Data reading completed successfully!\n",
      "The dataset is now loaded in DataFrame 'df' and ready for analysis.\n",
      "Next steps: You can now perform analysis and save results to: gs://my-dataproc-data-bucket-051203/output/product_sales_insights\n"
     ]
    }
   ],
   "source": [
    "print(\"=== Reading Order Data from GCS ===\")\n",
    "\n",
    "try:\n",
    "    # Read CSV file from GCS\n",
    "    print(f\"Reading data from: {input_file_path}\")\n",
    "    \n",
    "    df = spark.read \\\n",
    "        .option(\"header\", \"true\") \\\n",
    "        .option(\"inferSchema\", \"true\") \\\n",
    "        .option(\"timestampFormat\", \"yyyy-MM-dd\") \\\n",
    "        .csv(input_file_path)\n",
    "    \n",
    "    print(\"‚úÖ Data successfully loaded from GCS!\")\n",
    "    \n",
    "    # Display basic information about the dataset\n",
    "    print(f\"\\nüìä Dataset Overview:\")\n",
    "    print(f\"Total number of records: {df.count()}\")\n",
    "    print(f\"Number of columns: {len(df.columns)}\")\n",
    "    \n",
    "    # Show schema\n",
    "    print(f\"\\nüìã Data Schema:\")\n",
    "    df.printSchema()\n",
    "    \n",
    "    # Show column names\n",
    "    print(f\"\\nüìù Column Names:\")\n",
    "    for i, col_name in enumerate(df.columns, 1):\n",
    "        print(f\"{i}. {col_name}\")\n",
    "    \n",
    "    # Display first few rows\n",
    "    print(f\"\\nüîç First 10 rows of data:\")\n",
    "    df.show(10, truncate=False)\n",
    "    \n",
    "    # Check for any null values\n",
    "    print(f\"\\nüîç Null Value Check:\")\n",
    "    null_counts = df.select([count(when(col(c).isNull(), c)).alias(c) for c in df.columns])\n",
    "    null_counts.show()\n",
    "    \n",
    "    # Basic statistics for numerical columns\n",
    "    print(f\"\\nüìà Basic Statistics:\")\n",
    "    df.describe().show()\n",
    "    \n",
    "    # Data types verification\n",
    "    print(f\"\\nüè∑Ô∏è Data Types:\")\n",
    "    for field in df.schema.fields:\n",
    "        print(f\"{field.name}: {field.dataType}\")\n",
    "    \n",
    "    # Check unique values in categorical columns\n",
    "    print(f\"\\nüî¢ Unique Value Counts:\")\n",
    "    categorical_columns = ['CustomerID', 'ProductID', 'ProductName', 'Country']\n",
    "    \n",
    "    for column in categorical_columns:\n",
    "        if column in df.columns:\n",
    "            unique_count = df.select(column).distinct().count()\n",
    "            print(f\"{column}: {unique_count} unique values\")\n",
    "    \n",
    "    # Sample data validation\n",
    "    print(f\"\\n‚úÖ Data Quality Checks:\")\n",
    "    \n",
    "    # Check for duplicate rows\n",
    "    total_rows = df.count()\n",
    "    distinct_rows = df.distinct().count()\n",
    "    duplicates = total_rows - distinct_rows\n",
    "    print(f\"Duplicate rows: {duplicates}\")\n",
    "    \n",
    "    # Check date range\n",
    "    if 'OrderDate' in df.columns:\n",
    "        date_range = df.select(min('OrderDate').alias('min_date'), max('OrderDate').alias('max_date')).collect()[0]\n",
    "        print(f\"Date range: {date_range['min_date']} to {date_range['max_date']}\")\n",
    "    \n",
    "    # Check for negative quantities or prices\n",
    "    if 'Quantity' in df.columns:\n",
    "        negative_qty = df.filter(col('Quantity') < 0).count()\n",
    "        print(f\"Negative quantities: {negative_qty}\")\n",
    "    \n",
    "    if 'UnitPrice' in df.columns:\n",
    "        negative_price = df.filter(col('UnitPrice') < 0).count()\n",
    "        print(f\"Negative prices: {negative_price}\")\n",
    "    \n",
    "    # Show some sample records for each country\n",
    "    print(f\"\\nüåç Sample records by Country:\")\n",
    "    if 'Country' in df.columns:\n",
    "        countries = df.select('Country').distinct().collect()\n",
    "        for row in countries[:5]:  # Show first 5 countries\n",
    "            country = row['Country']\n",
    "            print(f\"\\n--- {country} ---\")\n",
    "            df.filter(col('Country') == country).show(3, truncate=False)\n",
    "    \n",
    "    print(f\"\\nüéâ Data reading completed successfully!\")\n",
    "    print(f\"The dataset is now loaded in DataFrame 'df' and ready for analysis.\")\n",
    "    print(f\"Next steps: You can now perform analysis and save results to: {output_path}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error reading data: {str(e)}\")\n",
    "    print(\"Please check:\")\n",
    "    print(\"1. File path is correct\")\n",
    "    print(\"2. File exists in the GCS bucket\")\n",
    "    print(\"3. Dataproc cluster has access to the bucket\")\n",
    "    print(\"4. CSV file format is correct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e0cbcec0-ca0e-48fd-98c9-fbf28beadd32",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2. Creating calculated columns...\n",
      "‚úÖ Data enrichment completed!\n"
     ]
    }
   ],
   "source": [
    "# Create calculated columns\n",
    "print(\"\\n2. Creating calculated columns...\")\n",
    "df_enriched = df.withColumn(\"TotalAmount\", col(\"Quantity\") * col(\"UnitPrice\")) \\\n",
    "    .withColumn(\"OrderDate\", to_date(col(\"OrderDate\"), \"yyyy-MM-dd\")) \\\n",
    "    .withColumn(\"Year\", year(col(\"OrderDate\"))) \\\n",
    "    .withColumn(\"Month\", month(col(\"OrderDate\"))) \\\n",
    "    .withColumn(\"DayOfWeek\", date_format(col(\"OrderDate\"), \"EEEE\")) \\\n",
    "    .withColumn(\"WeekOfYear\", weekofyear(col(\"OrderDate\")))\n",
    "\n",
    "# Cache the enriched dataframe for better performance\n",
    "df_enriched.cache()\n",
    "\n",
    "print(\"‚úÖ Data enrichment completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7ab44350-6da4-4909-98f8-3a216ba87de7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== üìä BUSINESS INSIGHTS ANALYSIS ===\n",
      "\n",
      "1Ô∏è‚É£ REVENUE ANALYSIS\n",
      "--------------------------------------------------\n",
      "üí∞ Total Revenue: $8,117.94\n",
      "üì¶ Total Orders: 17\n",
      "üë• Total Customers: 10\n",
      "üõçÔ∏è Total Products: 10\n",
      "üìã Total Line Items: 22\n",
      "üíµ Average Line Value: $369.00\n"
     ]
    }
   ],
   "source": [
    "# =================== ANALYSIS SECTION ===================\n",
    "\n",
    "print(\"\\n=== üìä BUSINESS INSIGHTS ANALYSIS ===\")\n",
    "\n",
    "# 1. REVENUE ANALYSIS\n",
    "print(\"\\n1Ô∏è‚É£ REVENUE ANALYSIS\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Total business metrics\n",
    "total_metrics = df_enriched.agg(\n",
    "    sum(\"TotalAmount\").alias(\"total_revenue\"),\n",
    "    count(\"*\").alias(\"total_line_items\"),\n",
    "    countDistinct(\"OrderID\").alias(\"total_orders\"),\n",
    "    countDistinct(\"CustomerID\").alias(\"total_customers\"),\n",
    "    countDistinct(\"ProductID\").alias(\"total_products\"),\n",
    "    avg(\"TotalAmount\").alias(\"avg_line_value\")\n",
    ").collect()[0]\n",
    "\n",
    "print(f\"üí∞ Total Revenue: ${total_metrics['total_revenue']:,.2f}\")\n",
    "print(f\"üì¶ Total Orders: {total_metrics['total_orders']:,}\")\n",
    "print(f\"üë• Total Customers: {total_metrics['total_customers']:,}\")\n",
    "print(f\"üõçÔ∏è Total Products: {total_metrics['total_products']:,}\")\n",
    "print(f\"üìã Total Line Items: {total_metrics['total_line_items']:,}\")\n",
    "print(f\"üíµ Average Line Value: ${total_metrics['avg_line_value']:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5a3b6839-af79-495b-976a-7829f0001dfd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üåç Revenue Performance by Country:\n",
      "+---------+------------------+---------+------+---------+------------------+--------------+\n",
      "|Country  |Revenue           |LineItems|Orders|Customers|AvgLineValue      |RevenuePercent|\n",
      "+---------+------------------+---------+------+---------+------------------+--------------+\n",
      "|USA      |3727.9799999999996|10       |6     |3        |372.79799999999994|45.92         |\n",
      "|UK       |2020.0            |4        |3     |2        |505.0             |24.88         |\n",
      "|Canada   |1220.0            |3        |3     |1        |406.6666666666667 |15.03         |\n",
      "|Australia|499.98            |2        |2     |1        |249.99            |6.16          |\n",
      "|Germany  |299.99            |1        |1     |1        |299.99            |3.7           |\n",
      "|Japan    |199.99            |1        |1     |1        |199.99            |2.46          |\n",
      "|France   |150.0             |1        |1     |1        |150.0             |1.85          |\n",
      "+---------+------------------+---------+------+---------+------------------+--------------+\n",
      "\n",
      "\n",
      "üìà Monthly Revenue Trend:\n",
      "+----+-----+-----------------+-------------+---------------+\n",
      "|Year|Month|   MonthlyRevenue|MonthlyOrders|ActiveCustomers|\n",
      "+----+-----+-----------------+-------------+---------------+\n",
      "|2024|    1|8117.939999999999|           17|             10|\n",
      "+----+-----+-----------------+-------------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Revenue by Country\n",
    "print(\"\\nüåç Revenue Performance by Country:\")\n",
    "country_revenue = df_enriched.groupBy(\"Country\") \\\n",
    "    .agg(\n",
    "        sum(\"TotalAmount\").alias(\"Revenue\"),\n",
    "        count(\"*\").alias(\"LineItems\"),\n",
    "        countDistinct(\"OrderID\").alias(\"Orders\"),\n",
    "        countDistinct(\"CustomerID\").alias(\"Customers\"),\n",
    "        avg(\"TotalAmount\").alias(\"AvgLineValue\")\n",
    "    ) \\\n",
    "    .withColumn(\"RevenuePercent\", round((col(\"Revenue\") / total_metrics['total_revenue']) * 100, 2)) \\\n",
    "    .orderBy(desc(\"Revenue\"))\n",
    "\n",
    "country_revenue.show(truncate=False)\n",
    "\n",
    "# Monthly Revenue Trend\n",
    "print(\"\\nüìà Monthly Revenue Trend:\")\n",
    "monthly_revenue = df_enriched.groupBy(\"Year\", \"Month\") \\\n",
    "    .agg(\n",
    "        sum(\"TotalAmount\").alias(\"MonthlyRevenue\"),\n",
    "        countDistinct(\"OrderID\").alias(\"MonthlyOrders\"),\n",
    "        countDistinct(\"CustomerID\").alias(\"ActiveCustomers\")\n",
    "    ) \\\n",
    "    .orderBy(\"Year\", \"Month\")\n",
    "\n",
    "monthly_revenue.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0e04f859-6dbb-4081-b5ac-668c5c0594ab",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2Ô∏è‚É£ CUSTOMER ANALYSIS\n",
      "--------------------------------------------------\n",
      "üèÜ Top 10 Customers by Revenue:\n",
      "+----------+----------+--------------+----------+--------------+---------+----------+----------+-----------------+----------------+-----------------+---------------+\n",
      "|CustomerID|TotalSpent|ItemsPurchased|OrderCount|UniqueProducts|Countries|FirstOrder|LastOrder |AvgLineValue     |CustomerLifeDays|AvgOrderValue    |CustomerSegment|\n",
      "+----------+----------+--------------+----------+--------------+---------+----------+----------+-----------------+----------------+-----------------+---------------+\n",
      "|CUST101   |2302.49   |6             |4         |5             |1        |2024-01-15|2024-01-27|383.7483333333333|12              |575.6225         |High Value     |\n",
      "|CUST103   |1720.0    |3             |2         |3             |1        |2024-01-18|2024-01-30|573.3333333333334|12              |860.0            |High Value     |\n",
      "|CUST108   |1249.99   |2             |1         |2             |1        |2024-01-25|2024-01-25|624.995          |0               |1249.99          |High Value     |\n",
      "|CUST102   |1220.0    |3             |3         |3             |1        |2024-01-16|2024-01-29|406.6666666666667|13              |406.6666666666667|Medium Value   |\n",
      "|CUST104   |499.98    |2             |2         |2             |1        |2024-01-19|2024-01-31|249.99           |12              |249.99           |Medium Value   |\n",
      "|CUST110   |300.0     |1             |1         |1             |1        |2024-01-28|2024-01-28|300.0            |0               |300.0            |Medium Value   |\n",
      "|CUST106   |299.99    |1             |1         |1             |1        |2024-01-22|2024-01-22|299.99           |0               |299.99           |Low Value      |\n",
      "|CUST109   |199.99    |1             |1         |1             |1        |2024-01-26|2024-01-26|199.99           |0               |199.99           |Low Value      |\n",
      "|CUST105   |175.5     |2             |1         |2             |1        |2024-01-20|2024-01-20|87.75            |0               |175.5            |Low Value      |\n",
      "|CUST107   |150.0     |1             |1         |1             |1        |2024-01-24|2024-01-24|150.0            |0               |150.0            |Low Value      |\n",
      "+----------+----------+--------------+----------+--------------+---------+----------+----------+-----------------+----------------+-----------------+---------------+\n",
      "\n",
      "\n",
      "üìä Customer Segmentation:\n",
      "+---------------+-------------+--------------+-------------------+--------------------+------------+\n",
      "|CustomerSegment|CustomerCount|SegmentRevenue|AvgSpendPerCustomer|AvgOrdersPerCustomer|RevenueShare|\n",
      "+---------------+-------------+--------------+-------------------+--------------------+------------+\n",
      "|Low Value      |4            |825.48        |206.37             |1.0                 |10.17       |\n",
      "|Medium Value   |3            |2019.98       |673.3266666666667  |2.0                 |24.88       |\n",
      "|High Value     |3            |5272.48       |1757.493333333333  |2.3333333333333335  |64.95       |\n",
      "+---------------+-------------+--------------+-------------------+--------------------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 2. CUSTOMER ANALYSIS\n",
    "print(\"\\n2Ô∏è‚É£ CUSTOMER ANALYSIS\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Customer behavior analysis\n",
    "customer_analysis = df_enriched.groupBy(\"CustomerID\") \\\n",
    "    .agg(\n",
    "        sum(\"TotalAmount\").alias(\"TotalSpent\"),\n",
    "        count(\"*\").alias(\"ItemsPurchased\"),\n",
    "        countDistinct(\"OrderID\").alias(\"OrderCount\"),\n",
    "        countDistinct(\"ProductID\").alias(\"UniqueProducts\"),\n",
    "        countDistinct(\"Country\").alias(\"Countries\"),\n",
    "        min(\"OrderDate\").alias(\"FirstOrder\"),\n",
    "        max(\"OrderDate\").alias(\"LastOrder\"),\n",
    "        avg(\"TotalAmount\").alias(\"AvgLineValue\")\n",
    "    ) \\\n",
    "    .withColumn(\"CustomerLifeDays\", datediff(col(\"LastOrder\"), col(\"FirstOrder\"))) \\\n",
    "    .withColumn(\"AvgOrderValue\", col(\"TotalSpent\") / col(\"OrderCount\"))\n",
    "\n",
    "# Customer segmentation based on spending\n",
    "customer_stats = customer_analysis.agg(\n",
    "    percentile_approx(\"TotalSpent\", 0.8).alias(\"high_value_threshold\"),\n",
    "    percentile_approx(\"TotalSpent\", 0.5).alias(\"medium_value_threshold\")\n",
    ").collect()[0]\n",
    "\n",
    "customer_segments = customer_analysis.withColumn(\n",
    "    \"CustomerSegment\",\n",
    "    when(col(\"TotalSpent\") >= customer_stats['high_value_threshold'], \"High Value\")\n",
    "    .when(col(\"TotalSpent\") >= customer_stats['medium_value_threshold'], \"Medium Value\")\n",
    "    .otherwise(\"Low Value\")\n",
    ")\n",
    "\n",
    "print(\"üèÜ Top 10 Customers by Revenue:\")\n",
    "customer_segments.orderBy(desc(\"TotalSpent\")).show(10, truncate=False)\n",
    "\n",
    "print(\"\\nüìä Customer Segmentation:\")\n",
    "segment_summary = customer_segments.groupBy(\"CustomerSegment\") \\\n",
    "    .agg(\n",
    "        count(\"*\").alias(\"CustomerCount\"),\n",
    "        sum(\"TotalSpent\").alias(\"SegmentRevenue\"),\n",
    "        avg(\"TotalSpent\").alias(\"AvgSpendPerCustomer\"),\n",
    "        avg(\"OrderCount\").alias(\"AvgOrdersPerCustomer\")\n",
    "    ) \\\n",
    "    .withColumn(\"RevenueShare\", round((col(\"SegmentRevenue\") / total_metrics['total_revenue']) * 100, 2))\n",
    "\n",
    "segment_summary.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2cf845e1-5ddd-4f6b-91b2-63f97213f706",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3Ô∏è‚É£ PRODUCT ANALYSIS\n",
      "--------------------------------------------------\n",
      "üèÜ Top 10 Products by Revenue:\n",
      "+---------+----------------+-----------------+------------+--------------+---------------+------------+------------+--------+--------+------------+-------------------+\n",
      "|ProductID|ProductName     |TotalQuantitySold|TotalRevenue|OrderFrequency|UniqueCustomers|UniqueOrders|AvgUnitPrice|MinPrice|MaxPrice|RevenueShare|AvgQuantityPerOrder|\n",
      "+---------+----------------+-----------------+------------+--------------+---------------+------------+------------+--------+--------+------------+-------------------+\n",
      "|PROD001  |Laptop A        |3                |3600.0      |3             |3              |3           |1200.0      |1200.0  |1200.0  |44.35       |1.0                |\n",
      "|PROD002  |Smartphone B    |2                |1700.0      |2             |2              |2           |850.0       |850.0   |850.0   |20.94       |1.0                |\n",
      "|PROD006  |Monitor 27in    |2                |600.0       |2             |2              |2           |300.0       |300.0   |300.0   |7.39        |1.0                |\n",
      "|PROD010  |Smartwatch X    |2                |599.98      |2             |2              |2           |299.99      |299.99  |299.99  |7.39        |1.0                |\n",
      "|PROD009  |Printer Laser   |2                |440.0       |2             |2              |2           |220.0       |220.0   |220.0   |5.42        |1.0                |\n",
      "|PROD007  |Headphones ANC  |2                |399.98      |2             |2              |2           |199.99      |199.99  |199.99  |4.93        |1.0                |\n",
      "|PROD008  |External SSD 1TB|2                |300.0       |2             |2              |2           |150.0       |150.0   |150.0   |3.7         |1.0                |\n",
      "|PROD004  |Keyboard Pro    |3                |225.0       |2             |2              |2           |75.0        |75.0    |75.0    |2.77        |1.5                |\n",
      "|PROD003  |Mouse XYZ       |6                |153.0       |3             |2              |3           |25.5        |25.5    |25.5    |1.88        |2.0                |\n",
      "|PROD005  |Webcam HD       |2                |99.98       |2             |2              |2           |49.99       |49.99   |49.99   |1.23        |1.0                |\n",
      "+---------+----------------+-----------------+------------+--------------+---------------+------------+------------+--------+--------+------------+-------------------+\n",
      "\n",
      "üìà Top 10 Products by Quantity Sold:\n",
      "+---------+----------------+-----------------+------------+--------------+---------------+------------+------------+--------+--------+------------+-------------------+\n",
      "|ProductID|ProductName     |TotalQuantitySold|TotalRevenue|OrderFrequency|UniqueCustomers|UniqueOrders|AvgUnitPrice|MinPrice|MaxPrice|RevenueShare|AvgQuantityPerOrder|\n",
      "+---------+----------------+-----------------+------------+--------------+---------------+------------+------------+--------+--------+------------+-------------------+\n",
      "|PROD003  |Mouse XYZ       |6                |153.0       |3             |2              |3           |25.5        |25.5    |25.5    |1.88        |2.0                |\n",
      "|PROD001  |Laptop A        |3                |3600.0      |3             |3              |3           |1200.0      |1200.0  |1200.0  |44.35       |1.0                |\n",
      "|PROD004  |Keyboard Pro    |3                |225.0       |2             |2              |2           |75.0        |75.0    |75.0    |2.77        |1.5                |\n",
      "|PROD006  |Monitor 27in    |2                |600.0       |2             |2              |2           |300.0       |300.0   |300.0   |7.39        |1.0                |\n",
      "|PROD005  |Webcam HD       |2                |99.98       |2             |2              |2           |49.99       |49.99   |49.99   |1.23        |1.0                |\n",
      "|PROD009  |Printer Laser   |2                |440.0       |2             |2              |2           |220.0       |220.0   |220.0   |5.42        |1.0                |\n",
      "|PROD002  |Smartphone B    |2                |1700.0      |2             |2              |2           |850.0       |850.0   |850.0   |20.94       |1.0                |\n",
      "|PROD010  |Smartwatch X    |2                |599.98      |2             |2              |2           |299.99      |299.99  |299.99  |7.39        |1.0                |\n",
      "|PROD007  |Headphones ANC  |2                |399.98      |2             |2              |2           |199.99      |199.99  |199.99  |4.93        |1.0                |\n",
      "|PROD008  |External SSD 1TB|2                |300.0       |2             |2              |2           |150.0       |150.0   |150.0   |3.7         |1.0                |\n",
      "+---------+----------------+-----------------+------------+--------------+---------------+------------+------------+--------+--------+------------+-------------------+\n",
      "\n",
      "üë• Top 10 Products by Customer Reach:\n",
      "+---------+----------------+-----------------+------------+--------------+---------------+------------+------------+--------+--------+------------+-------------------+\n",
      "|ProductID|ProductName     |TotalQuantitySold|TotalRevenue|OrderFrequency|UniqueCustomers|UniqueOrders|AvgUnitPrice|MinPrice|MaxPrice|RevenueShare|AvgQuantityPerOrder|\n",
      "+---------+----------------+-----------------+------------+--------------+---------------+------------+------------+--------+--------+------------+-------------------+\n",
      "|PROD001  |Laptop A        |3                |3600.0      |3             |3              |3           |1200.0      |1200.0  |1200.0  |44.35       |1.0                |\n",
      "|PROD006  |Monitor 27in    |2                |600.0       |2             |2              |2           |300.0       |300.0   |300.0   |7.39        |1.0                |\n",
      "|PROD005  |Webcam HD       |2                |99.98       |2             |2              |2           |49.99       |49.99   |49.99   |1.23        |1.0                |\n",
      "|PROD009  |Printer Laser   |2                |440.0       |2             |2              |2           |220.0       |220.0   |220.0   |5.42        |1.0                |\n",
      "|PROD002  |Smartphone B    |2                |1700.0      |2             |2              |2           |850.0       |850.0   |850.0   |20.94       |1.0                |\n",
      "|PROD010  |Smartwatch X    |2                |599.98      |2             |2              |2           |299.99      |299.99  |299.99  |7.39        |1.0                |\n",
      "|PROD003  |Mouse XYZ       |6                |153.0       |3             |2              |3           |25.5        |25.5    |25.5    |1.88        |2.0                |\n",
      "|PROD007  |Headphones ANC  |2                |399.98      |2             |2              |2           |199.99      |199.99  |199.99  |4.93        |1.0                |\n",
      "|PROD008  |External SSD 1TB|2                |300.0       |2             |2              |2           |150.0       |150.0   |150.0   |3.7         |1.0                |\n",
      "|PROD004  |Keyboard Pro    |3                |225.0       |2             |2              |2           |75.0        |75.0    |75.0    |2.77        |1.5                |\n",
      "+---------+----------------+-----------------+------------+--------------+---------------+------------+------------+--------+--------+------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 3. PRODUCT ANALYSIS\n",
    "print(\"\\n3Ô∏è‚É£ PRODUCT ANALYSIS\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Product performance analysis\n",
    "product_analysis = df_enriched.groupBy(\"ProductID\", \"ProductName\") \\\n",
    "    .agg(\n",
    "        sum(\"Quantity\").alias(\"TotalQuantitySold\"),\n",
    "        sum(\"TotalAmount\").alias(\"TotalRevenue\"),\n",
    "        count(\"*\").alias(\"OrderFrequency\"),\n",
    "        countDistinct(\"CustomerID\").alias(\"UniqueCustomers\"),\n",
    "        countDistinct(\"OrderID\").alias(\"UniqueOrders\"),\n",
    "        avg(\"UnitPrice\").alias(\"AvgUnitPrice\"),\n",
    "        min(\"UnitPrice\").alias(\"MinPrice\"),\n",
    "        max(\"UnitPrice\").alias(\"MaxPrice\")\n",
    "    ) \\\n",
    "    .withColumn(\"RevenueShare\", round((col(\"TotalRevenue\") / total_metrics['total_revenue']) * 100, 2)) \\\n",
    "    .withColumn(\"AvgQuantityPerOrder\", col(\"TotalQuantitySold\") / col(\"UniqueOrders\"))\n",
    "\n",
    "print(\"üèÜ Top 10 Products by Revenue:\")\n",
    "product_analysis.orderBy(desc(\"TotalRevenue\")).show(10, truncate=False)\n",
    "\n",
    "print(\"üìà Top 10 Products by Quantity Sold:\")\n",
    "product_analysis.orderBy(desc(\"TotalQuantitySold\")).show(10, truncate=False)\n",
    "\n",
    "print(\"üë• Top 10 Products by Customer Reach:\")\n",
    "product_analysis.orderBy(desc(\"UniqueCustomers\")).show(10, truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "eee2914f-e1b8-4471-8229-36c9b827402c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "4Ô∏è‚É£ ORDER PATTERN ANALYSIS\n",
      "--------------------------------------------------\n",
      "üìä Order Size Distribution:\n",
      "+------------+----------+------------------+\n",
      "|ProductLines|OrderCount|     AvgOrderValue|\n",
      "+------------+----------+------------------+\n",
      "|           1|        12|318.03833333333336|\n",
      "|           2|         5| 860.2959999999999|\n",
      "+------------+----------+------------------+\n",
      "\n",
      "üí∞ Order Value Distribution by Country:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 133:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+-----------------+-------------+-------------+------------------+\n",
      "|Country  |OrderCount|AvgOrderValue    |MinOrderValue|MaxOrderValue|AvgItemsPerOrder  |\n",
      "+---------+----------+-----------------+-------------+-------------+------------------+\n",
      "|UK       |3         |673.3333333333334|220.0        |1500.0       |1.3333333333333333|\n",
      "|USA      |6         |621.3299999999999|76.5         |1251.0       |2.1666666666666665|\n",
      "|Canada   |3         |406.6666666666667|150.0        |850.0        |1.0               |\n",
      "|Germany  |1         |299.99           |299.99       |299.99       |1.0               |\n",
      "|Australia|2         |249.99           |199.99       |299.99       |1.0               |\n",
      "|Japan    |1         |199.99           |199.99       |199.99       |1.0               |\n",
      "|France   |1         |150.0            |150.0        |150.0        |2.0               |\n",
      "+---------+----------+-----------------+-------------+-------------+------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# 4. ORDER PATTERN ANALYSIS\n",
    "print(\"\\n4Ô∏è‚É£ ORDER PATTERN ANALYSIS\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Order-level analysis\n",
    "order_analysis = df_enriched.groupBy(\"OrderID\") \\\n",
    "    .agg(\n",
    "        sum(\"TotalAmount\").alias(\"OrderValue\"),\n",
    "        sum(\"Quantity\").alias(\"TotalItems\"),\n",
    "        count(\"*\").alias(\"ProductLines\"),\n",
    "        countDistinct(\"ProductID\").alias(\"UniqueProducts\"),\n",
    "        first(\"CustomerID\").alias(\"CustomerID\"),\n",
    "        first(\"OrderDate\").alias(\"OrderDate\"),\n",
    "        first(\"Country\").alias(\"Country\")\n",
    "    )\n",
    "\n",
    "print(\"üìä Order Size Distribution:\")\n",
    "order_size_dist = order_analysis.groupBy(\"ProductLines\") \\\n",
    "    .agg(\n",
    "        count(\"*\").alias(\"OrderCount\"),\n",
    "        avg(\"OrderValue\").alias(\"AvgOrderValue\")\n",
    "    ) \\\n",
    "    .orderBy(\"ProductLines\")\n",
    "\n",
    "order_size_dist.show()\n",
    "\n",
    "print(\"üí∞ Order Value Distribution by Country:\")\n",
    "country_order_analysis = order_analysis.groupBy(\"Country\") \\\n",
    "    .agg(\n",
    "        count(\"*\").alias(\"OrderCount\"),\n",
    "        avg(\"OrderValue\").alias(\"AvgOrderValue\"),\n",
    "        min(\"OrderValue\").alias(\"MinOrderValue\"),\n",
    "        max(\"OrderValue\").alias(\"MaxOrderValue\"),\n",
    "        avg(\"TotalItems\").alias(\"AvgItemsPerOrder\")\n",
    "    ) \\\n",
    "    .orderBy(desc(\"AvgOrderValue\"))\n",
    "\n",
    "country_order_analysis.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1eddfdcd-fb37-43ad-9ab1-afdd5f14d971",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5Ô∏è‚É£ TIME-BASED ANALYSIS\n",
      "--------------------------------------------------\n",
      "üìÖ Daily Sales Performance:\n",
      "+----------+------------------+-----------+---------------+---------+\n",
      "| OrderDate|      DailyRevenue|DailyOrders|ActiveCustomers|ItemsSold|\n",
      "+----------+------------------+-----------+---------------+---------+\n",
      "|2024-01-15|            1251.0|          1|              1|        3|\n",
      "|2024-01-16|             850.0|          1|              1|        1|\n",
      "|2024-01-17|124.99000000000001|          1|              1|        2|\n",
      "|2024-01-18|            1500.0|          1|              1|        2|\n",
      "|2024-01-19|            199.99|          1|              1|        1|\n",
      "|2024-01-20|             175.5|          1|              1|        2|\n",
      "|2024-01-21|             220.0|          1|              1|        1|\n",
      "|2024-01-22|            299.99|          1|              1|        1|\n",
      "|2024-01-23|             850.0|          1|              1|        1|\n",
      "|2024-01-24|             150.0|          1|              1|        2|\n",
      "|2024-01-25|           1249.99|          1|              1|        2|\n",
      "|2024-01-26|            199.99|          1|              1|        1|\n",
      "|2024-01-27|              76.5|          1|              1|        3|\n",
      "|2024-01-28|             300.0|          1|              1|        1|\n",
      "|2024-01-29|             150.0|          1|              1|        1|\n",
      "|2024-01-30|             220.0|          1|              1|        1|\n",
      "|2024-01-31|            299.99|          1|              1|        1|\n",
      "+----------+------------------+-----------+---------------+---------+\n",
      "\n",
      "üìä Day of Week Performance:\n",
      "+---------+-------+------+------------+\n",
      "|DayOfWeek|Revenue|Orders|AvgLineValue|\n",
      "+---------+-------+------+------------+\n",
      "| Thursday|2749.99|     2|    687.4975|\n",
      "|  Tuesday| 1920.0|     3|       640.0|\n",
      "|   Monday|1700.99|     3|    425.2475|\n",
      "|Wednesday| 574.98|     3|     143.745|\n",
      "|   Sunday|  520.0|     2|       260.0|\n",
      "|   Friday| 399.98|     2|      199.99|\n",
      "| Saturday|  252.0|     2|        84.0|\n",
      "+---------+-------+------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 5. TIME-BASED ANALYSIS\n",
    "print(\"\\n5Ô∏è‚É£ TIME-BASED ANALYSIS\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "print(\"üìÖ Daily Sales Performance:\")\n",
    "daily_analysis = df_enriched.groupBy(\"OrderDate\") \\\n",
    "    .agg(\n",
    "        sum(\"TotalAmount\").alias(\"DailyRevenue\"),\n",
    "        countDistinct(\"OrderID\").alias(\"DailyOrders\"),\n",
    "        countDistinct(\"CustomerID\").alias(\"ActiveCustomers\"),\n",
    "        sum(\"Quantity\").alias(\"ItemsSold\")\n",
    "    ) \\\n",
    "    .orderBy(\"OrderDate\")\n",
    "\n",
    "daily_analysis.show()\n",
    "\n",
    "print(\"üìä Day of Week Performance:\")\n",
    "dow_analysis = df_enriched.groupBy(\"DayOfWeek\") \\\n",
    "    .agg(\n",
    "        sum(\"TotalAmount\").alias(\"Revenue\"),\n",
    "        countDistinct(\"OrderID\").alias(\"Orders\"),\n",
    "        avg(\"TotalAmount\").alias(\"AvgLineValue\")\n",
    "    ) \\\n",
    "    .orderBy(desc(\"Revenue\"))\n",
    "\n",
    "dow_analysis.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5ce2443c-266d-4cc6-aa52-834a74a044c6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "6Ô∏è‚É£ CROSS-SELL OPPORTUNITIES\n",
      "--------------------------------------------------\n",
      "üîó Top Product Combinations (Cross-sell Opportunities):\n",
      "+------------+----------------+------------+\n",
      "|Product1    |Product2        |CoOccurrence|\n",
      "+------------+----------------+------------+\n",
      "|Keyboard Pro|Webcam HD       |1           |\n",
      "|Laptop A    |Monitor 27in    |1           |\n",
      "|Mouse XYZ   |External SSD 1TB|1           |\n",
      "|Laptop A    |Mouse XYZ       |1           |\n",
      "|Laptop A    |Webcam HD       |1           |\n",
      "+------------+----------------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 6. CROSS-SELL ANALYSIS\n",
    "print(\"\\n6Ô∏è‚É£ CROSS-SELL OPPORTUNITIES\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Products frequently bought together\n",
    "cross_sell = df.alias(\"a\").join(\n",
    "    df.alias(\"b\"),\n",
    "    (col(\"a.OrderID\") == col(\"b.OrderID\")) & \n",
    "    (col(\"a.ProductID\") < col(\"b.ProductID\"))  # Avoid duplicates\n",
    ") \\\n",
    ".groupBy(\n",
    "    col(\"a.ProductName\").alias(\"Product1\"),\n",
    "    col(\"b.ProductName\").alias(\"Product2\")\n",
    ") \\\n",
    ".agg(count(\"*\").alias(\"CoOccurrence\")) \\\n",
    ".orderBy(desc(\"CoOccurrence\"))\n",
    "\n",
    "print(\"üîó Top Product Combinations (Cross-sell Opportunities):\")\n",
    "cross_sell.show(15, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4f309662-96dd-4e3b-87ec-2e8891bfc723",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== üíæ SAVING ANALYSIS RESULTS TO GCS ===\n",
      "Saving country revenue analysis...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving customer segmentation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving product performance analysis...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving order pattern analysis...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving daily sales trends...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving cross-sell opportunities...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving enriched dataset as Parquet...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating and saving executive summary...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üéâ ALL ANALYSIS RESULTS SAVED SUCCESSFULLY!\n",
      "üìÇ Results Location: gs://my-dataproc-data-bucket-051203/output/product_sales_insights/\n",
      "\n",
      "üìã Files Created:\n",
      "   ‚îú‚îÄ‚îÄ country_analysis/ (CSV)\n",
      "   ‚îú‚îÄ‚îÄ customer_segmentation/ (CSV)\n",
      "   ‚îú‚îÄ‚îÄ product_performance/ (CSV)\n",
      "   ‚îú‚îÄ‚îÄ order_patterns/ (CSV)\n",
      "   ‚îú‚îÄ‚îÄ daily_sales_trends/ (CSV)\n",
      "   ‚îú‚îÄ‚îÄ cross_sell_opportunities/ (CSV)\n",
      "   ‚îú‚îÄ‚îÄ executive_summary/ (CSV)\n",
      "   ‚îî‚îÄ‚îÄ enriched_order_data/ (Parquet, partitioned)\n",
      "\n",
      "‚ú® Analysis Complete! You can now access all insights from your GCS bucket.\n"
     ]
    }
   ],
   "source": [
    "# =================== SAVE RESULTS ===================\n",
    "\n",
    "print(\"\\n=== üíæ SAVING ANALYSIS RESULTS TO GCS ===\")\n",
    "\n",
    "try:\n",
    "    # 1. Save Country Analysis\n",
    "    print(\"Saving country revenue analysis...\")\n",
    "    country_revenue.coalesce(1).write.mode(\"overwrite\") \\\n",
    "        .option(\"header\", \"true\") \\\n",
    "        .csv(f\"{output_path}/country_analysis\")\n",
    "    \n",
    "    # 2. Save Customer Segmentation\n",
    "    print(\"Saving customer segmentation...\")\n",
    "    customer_segments.coalesce(1).write.mode(\"overwrite\") \\\n",
    "        .option(\"header\", \"true\") \\\n",
    "        .csv(f\"{output_path}/customer_segmentation\")\n",
    "    \n",
    "    # 3. Save Product Analysis\n",
    "    print(\"Saving product performance analysis...\")\n",
    "    product_analysis.coalesce(1).write.mode(\"overwrite\") \\\n",
    "        .option(\"header\", \"true\") \\\n",
    "        .csv(f\"{output_path}/product_performance\")\n",
    "    \n",
    "    # 4. Save Order Analysis\n",
    "    print(\"Saving order pattern analysis...\")\n",
    "    order_analysis.coalesce(1).write.mode(\"overwrite\") \\\n",
    "        .option(\"header\", \"true\") \\\n",
    "        .csv(f\"{output_path}/order_patterns\")\n",
    "    \n",
    "    # 5. Save Time Analysis\n",
    "    print(\"Saving daily sales trends...\")\n",
    "    daily_analysis.coalesce(1).write.mode(\"overwrite\") \\\n",
    "        .option(\"header\", \"true\") \\\n",
    "        .csv(f\"{output_path}/daily_sales_trends\")\n",
    "    \n",
    "    # 6. Save Cross-sell Analysis\n",
    "    print(\"Saving cross-sell opportunities...\")\n",
    "    cross_sell.coalesce(1).write.mode(\"overwrite\") \\\n",
    "        .option(\"header\", \"true\") \\\n",
    "        .csv(f\"{output_path}/cross_sell_opportunities\")\n",
    "    \n",
    "    # 7. Save Enriched Dataset (Parquet for efficiency)\n",
    "    print(\"Saving enriched dataset as Parquet...\")\n",
    "    df_enriched.write.mode(\"overwrite\") \\\n",
    "        .partitionBy(\"Country\", \"Year\") \\\n",
    "        .parquet(f\"{output_path}/enriched_order_data\")\n",
    "    \n",
    "    # 8. Save Summary Statistics\n",
    "    print(\"Creating and saving executive summary...\")\n",
    "    \n",
    "    # Create summary dataframe\n",
    "    summary_data = [\n",
    "        (\"Total Revenue\", f\"${total_metrics['total_revenue']:,.2f}\"),\n",
    "        (\"Total Orders\", f\"{total_metrics['total_orders']:,}\"),\n",
    "        (\"Total Customers\", f\"{total_metrics['total_customers']:,}\"),\n",
    "        (\"Total Products\", f\"{total_metrics['total_products']:,}\"),\n",
    "        (\"Average Order Value\", f\"${(total_metrics['total_revenue']/total_metrics['total_orders']):.2f}\"),\n",
    "        (\"Top Country by Revenue\", country_revenue.first()['Country']),\n",
    "        (\"Date Range\", f\"{df_enriched.agg(min('OrderDate')).collect()[0][0]} to {df_enriched.agg(max('OrderDate')).collect()[0][0]}\")\n",
    "    ]\n",
    "    \n",
    "    summary_df = spark.createDataFrame(summary_data, [\"Metric\", \"Value\"])\n",
    "    summary_df.coalesce(1).write.mode(\"overwrite\") \\\n",
    "        .option(\"header\", \"true\") \\\n",
    "        .csv(f\"{output_path}/executive_summary\")\n",
    "    \n",
    "    print(\"\\nüéâ ALL ANALYSIS RESULTS SAVED SUCCESSFULLY!\")\n",
    "    print(f\"üìÇ Results Location: {output_path}/\")\n",
    "    print(\"\\nüìã Files Created:\")\n",
    "    print(\"   ‚îú‚îÄ‚îÄ country_analysis/ (CSV)\")\n",
    "    print(\"   ‚îú‚îÄ‚îÄ customer_segmentation/ (CSV)\")\n",
    "    print(\"   ‚îú‚îÄ‚îÄ product_performance/ (CSV)\")\n",
    "    print(\"   ‚îú‚îÄ‚îÄ order_patterns/ (CSV)\")  \n",
    "    print(\"   ‚îú‚îÄ‚îÄ daily_sales_trends/ (CSV)\")\n",
    "    print(\"   ‚îú‚îÄ‚îÄ cross_sell_opportunities/ (CSV)\")\n",
    "    print(\"   ‚îú‚îÄ‚îÄ executive_summary/ (CSV)\")\n",
    "    print(\"   ‚îî‚îÄ‚îÄ enriched_order_data/ (Parquet, partitioned)\")\n",
    "    \n",
    "    print(f\"\\n‚ú® Analysis Complete! You can now access all insights from your GCS bucket.\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error saving results: {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b2ce378b-4b50-4d07-b73c-1712a364efae",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîö Spark session ended. Analysis pipeline completed successfully!\n"
     ]
    }
   ],
   "source": [
    "# Clean up\n",
    "df_enriched.unpersist()\n",
    "spark.stop()\n",
    "\n",
    "print(\"\\nüîö Spark session ended. Analysis pipeline completed successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "python",
   "name": "pyspark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
